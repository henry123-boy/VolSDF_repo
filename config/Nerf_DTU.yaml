_parent_: config/base.yaml

arch:                                                       # architectural optionss
    layers_feat: [null,256,256,256,217,256,256,256,256,256] # hidden layers for occupancy filed with uncertainty MLP
    layers_rgb: [null,256,256,256,256,3]                 # hidden layers for appearance MLP
    skip: [4]                                               # skip connections
    posenc:                                                 # positional encoding:
        L_3D: 6                                            # number of bases (3D point)
        L_view: 0                                           # number of bases (viewpoint)
    density_activ: softplus                                 # activation function for output volume density
    tf_init: true                                           # initialize network weights in TensorFlow style
VolSDF:
    obj_bounding_radius: 1.0                               # scene sphere, as in the VolSDF paper
nerf:                                                       # VolSDF options
    hash_version: true
    out_hash_version: true
    view_dep: true                                          # condition MLP on viewpoint
    fine_sampling: false
    sample_stratified: true                                 # stratified sampling
    density_noise_reg:                                      # Gaussian noise on density output as regularization
    depth:                                                  # depth-related options
        param: metric                                      # depth parametrization (for sampling along the ray)
        min_d: 0.0
        max_d: 2                                            # In VolSDF the max depth is 2*r
    outside_scene: "builtin"                               # choice from [builtin,nerfplusplus], the rendering for the background
    sample_intvs: 128                                       # the init number of samples
    final_sample_intvs: 64                                 # according to paper the final sample intervals are 64
    rand_rays: 4096                                          # number of random rays for each step
    setbg_opaque: true
data:                                                       # data options
    dataset: DTU                                           # dataset name
    val_on_test: true
    bgcolor: 0
    scene:
    root: /remote-home/xyx/remote/NeRF2V_xyx/datasets/DTU
    train_img_size: [1200,1600]                                   # input image sizes [height,width]    the raw size [1200,1600] only support scale HW same time
    val_img_size: [150,200]
    scale_radius: 3.0                                       # scale all the cameras to be within this radius
    num_workers: 4                                          # number of parallel workers for data loading
    preload: true                                           # preload the entire dataset into the memory
    val_ratio: 0.1                                          # ratio of sequence split for validation

camera:                                                     # camera options
    model: perspective                                      # type of camera model
    ndc: false                                              # reparametrize as normalized device coordinates (NDC)
    noise: false

loss_weight:                                                # loss weights (in log scale)
    render: 0                                               # RGB rendering loss
    render_fine:

optim:                                                      # optimization options
    lr: 2.e-3                                               # learning rate (main)
    lr_end: 4.e-4                                           # terminal learning rate (only used with sched.type=ExponentialLR)
    sched:                                                  # learning rate scheduling options
        type: ExponentialLR                                 # scheduler (see PyTorch doc)
        gamma:                                               # decay rate (can be empty if lr_end were specified)
visdom:
    cam_depth: 0.01
batch_size: 1                                                # batch size
max_epoch:                                                  # train to maximum number of epochs (not used for NeRF/BARF)
max_iter: 100000                                            # train to maximum number of iterations
H: 1200                                                      # the img H
W: 1600                                                      # the img W
freq:                                                       # periodic actions during training
    scalar: 100                                             # log losses and scalar states (every N iterations)
    vis: 100                                               # visualize results (every N iterations)
    val: 500                                               # validate on val set (every N iterations)
    ckpt: 5000                                             # save checkpoint (every N iterations)
    vis_mesh: 10000                                            # the freq to visualize mesh
